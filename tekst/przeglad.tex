\section{Przegląd literatury i stanu wiedzy}
\label{sec:przeglad_literatury}

\textbf{Era autonomicznych systemów latających}

Bezzałogowe statki powietrzne (BSP), potocznie zwane dronami, zrewolucjonizowały wiele dziedzin życia i przemysłu, od filmografii i rozrywki, przez rolnictwo precyzyjne, inspekcje infrastruktury, aż po zastosowania w bezpieczeństwie i obronności. Ich wszechstronność wynika w dużej mierze z możliwości przenoszenia różnorodnych sensorów, w tym kamer światła widzialnego (RGB), które stały się podstawowym źródłem informacji o otoczeniu. Wraz z rosnącą dostępnością i zaawansowaniem technologicznym BSP, kluczowym kierunkiem rozwoju staje się zwiększanie ich~autonomii \cite{bsp_autonomy_review}. Zdolność do samodzielnego postrzegania, rozumienia i reagowania na otoczenie jest fundamentem tej autonomii, a jednym z jej podstawowych elementów jest efektywna detekcja i śledzenie obiektów w czasie rzeczywistym na podstawie obrazu z kamery. Niniejsza praca koncentruje się właśnie na tym wyzwaniu, eksplorując możliwości implementacji takiego systemu na platformie BSP o ograniczonych zasobach.
\\ \newline
\textbf{Wyzwania wizyjnej detekcji i śledzenia obiektów na BSP}

Implementacja systemów wizyjnych na pokładach BSP napotyka szereg specyficznych wyzwań, które odróżniają je od stacjonarnych systemów monitoringu. Przede wszystkim, platformy latające charakteryzują się \textbf{ograniczonymi zasobami obliczeniowymi, energetycznymi oraz wagowymi} \cite{bsp_constraints_review}. To narzuca konieczność stosowania algorytmów zoptymalizowanych pod kątem wydajności, często kosztem pewnej precyzji, jak również doboru lekkich komponentów sprzętowych. 

Kolejnym istotnym problemem są \textbf{dynamiczne warunki pracy}. BSP operują w zmiennym środowisku: zmieniające się oświetlenie (słońce, cienie, chmury), warunki atmosferyczne (mgła, deszcz), a także nieprzewidywalny ruch tła i samych śledzonych obiektów stanowią poważne wyzwanie dla algorytmów wizyjnych \cite{bsp_vision_challenges}. Co więcej, sam ruch BSP oraz wibracje generowane przez silniki i śmigła wprowadzają \textbf{zakłócenia w obrazie}, takie jak rozmycie ruchu (motion blur) czy drgania, które negatywnie wpływają na jakość detekcji i stabilność śledzenia \cite{bsp_vibration_impact}. Konieczność radzenia sobie z tymi problemami motywuje do poszukiwania zarówno zaawansowanych algorytmów przetwarzania obrazu, jak i rozwiązań mechanicznych stabilizujących kamerę.
\\ \newline
\textbf{Przegląd metod detekcji i śledzenia obiektów}

Literatura oferuje szeroki wachlarz metod detekcji i śledzenia obiektów, które można podzielić na dwie główne kategorie: metody klasyczne oraz oparte na głębokim uczeniu.

\textbf{Metody klasyczne}, takie jak kaskady cech Haara \cite{opencv, viola2001rapid}, detektory cech lokalnych (np. SIFT, SURF, HOG) czy metody oparte na dopasowaniu szablonów i analizie ruchu (np. Optical Flow), charakteryzują się zazwyczaj niskimi wymaganiami obliczeniowymi \cite{classic_detection_review}. Kaskady Haara działają bardzo wydajnie, umożliwiając przetwarzanie w czasie rzeczywistym. Ich głównym ograniczeniem jest jednak mniejsza elastyczność i dokładność w porównaniu do nowszych metod, szczególnie w złożonych scenach i przy detekcji różnorodnych obiektów.

\textbf{Metody oparte na głębokim uczeniu (Deep Learning)}, w szczególności konwolucyjne sieci neuronowe (CNN), zdominowały w ostatnich latach dziedzinę detekcji obiektów, oferując znacznie wyższą skuteczność \cite{dl_detection_review}. Architektury takie jak YOLO (You Only Look Once)  \cite{yolo}, SSD (Single Shot MultiBox Detector) \cite{liu2016ssd} czy Faster R-CNN \cite{ren2015faster} osiągają imponujące wyniki na standardowych benchmarkach. Rozwój lżejszych wariantów, takich jak YOLOv4-tiny czy MobileNet-SSD \cite{howard2017mobilenets}, stara się znaleźć kompromis między dokładnością a szybkością działania. Po detekcji obiektu kluczowe staje się jego \textbf{śledzenie (tracking)}. Algorytmy śledzenia, takie jak filtry Kalmana, filtry cząsteczkowe, algorytmy korelacyjne (np. MOSSE, KCF) \cite{tracking_review} czy nowsze metody oparte na DL (np. SORT, DeepSORT) \cite{bewley2016sort, wojke2017deepsort}, pozwalają na utrzymanie tożsamości obiektu między klatkami, nawet w przypadku chwilowych zaników detekcji. Wybór odpowiedniego algorytmu śledzenia również zależy od dostępnych zasobów i wymagań aplikacji.
\\ \newline
\textbf{Stabilizacja mechaniczna i rozwiązania systemowe}

Aby przeciwdziałać negatywnemu wpływowi ruchu BSP i wibracji na jakość obrazu, powszechnie stosuje się \textbf{mechaniczne systemy stabilizacji kamery, zwane gimbalami}. Rozwiązania te sięgają od prostych, jednoosiowych konstrukcji sterowanych serwomechanizmami, takich jak te oparte na projektach open-source \cite{medlin}, aż po zaawansowane, wieloosiowe gimbale wykorzystujące silniki bezszczotkowe (BLDC), zapewniające znacznie płynniejszą i dokładniejszą stabilizację \cite{gimbaldiy}. Rozwiązania komercyjne, takie jak te oferowane przez firmę DJI \cite{dji_website}, integrują zaawansowane gimbale z algorytmami wizyjnymi, oferując gotowe systemy śledzenia i autonomicznych lotów. Jednak są to często systemy zamknięte i kosztowne. Na rynku istnieją również bardziej specjalistyczne rozwiązania, np. w sektorze obronnym (firma Anduril \cite{anduril_website}), które pokazują potencjał integracji zaawansowanej wizji i mechaniki, ale są one poza zasięgiem typowych zastosowań cywilnych i akademickich.
\newpage 
% \\ \newline
\textbf{Identyfikacja luki badawczej i uzasadnienie celu pracy}

Pomimo bogatej literatury i dostępności różnorodnych algorytmów oraz komponentów, nadal istnieje luka w zakresie kompleksowych, dobrze udokumentowanych i przetestowanych rozwiązań do detekcji i śledzenia obiektów, które byłyby zoptymalizowane pod kątem specyficznych ograniczeń niskokosztowych platform BSP. Wiele badań skupia się albo na samych algorytmach, testowanych często na wydajnych komputerach PC, albo na zaawansowanych, drogich systemach komercyjnych. Brakuje natomiast prac demonstrujących praktyczną integrację i ewaluację \textit{całego} systemu – od lekkiej mechaniki, przez dobór i optymalizację algorytmów wizyjnych (balansujących dokładność i wydajność na konkretnym sprzęcie wbudowanym), po system sterowania – w kontekście realnych ograniczeń platformy BSP.

Niniejsza praca ma na celu wypełnienie tej luki poprzez zaprojektowanie, zbudowanie i przetestowanie zintegrowanego systemu detekcji i śledzenia obiektów dla BSP. Praca skupi się na analizie kompromisu między wydajnością a dokładnością wybranych algorytmów wizyjnych w kontekście realnych zasobów sprzętowych oraz na opracowaniu pętli sterowania umożliwiającej śledzenie obiektu poprzez ruch kamery. Celem jest stworzenie funkcjonalnego prototypu, który stanowiłby podstawę do dalszych badań i rozwoju tanich, autonomicznych systemów wizyjnych dla BSP, a także dostarczenie praktycznych wniosków dotyczących implementacji takich systemów.